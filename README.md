Term frequency–inverse document frequency

In information retrieval, tf–idf (also TF*IDF, TFIDF, TF–IDF, or Tf–idf), short for term frequency–inverse document frequency,
is a measure of importance of a word to a document in a collection or corpus, adjusted for the fact that some words appear more frequently in general.[1]
It was often used as a weighting factor in searches of information retrieval, text mining, and user modeling.
A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries used tf–idf.[2] 

https://en.wikipedia.org/wiki/Tf%E2%80%93idf
